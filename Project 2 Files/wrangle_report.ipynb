{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report for Project 2 - Wrangle and Analyse Data\n",
    "by Kudakwashe Verah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "To wrangle and analyse data from the @WeRateDogs's archive of tweets so as to create insightful and visual analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Details\n",
    "- Gathered data from 3 different sources,\n",
    "- Assessed the datasets for quality and tidiness issues,\n",
    "- Cleaned the data by addressing the quality and tidiness issues.\n",
    ">\n",
    "- We had 2,356 tweets after the API query that we assessed for quality and tidiness issues before we cleaned and analysed the data.\n",
    ">\n",
    "- The @WeRateDogs Twitter Channel posts pictures of dogs with a short description of the dog was engaged in, and rates the dog out of 10 or sometimes more. The rating is never below zero but it can go beyond 10/10.\n",
    "    - They also classify dogs under 4 separate groups based on their development: doggo, floofer, pupper, and puppo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling Process\n",
    "\n",
    "### Gathering\n",
    "We gathered the data from 3 different sources and saved it in 3 different file formats.\n",
    "\n",
    "1. Twitter Archive Enhanced CSV file downloaded from the Udacity website: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv\n",
    "2. Twitter Image Predictions TSV file downloaded using the requests library: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "3. Tweets queried as JSON data via the Tweepy library to access the Twitter API, saved as `df_json.txt`.\n",
    "\n",
    "### Assessing\n",
    "- We were looking for 8 quality and 2 tidiness issues for all the datasets. It must be noted that there are more than 8 quality and 2 tidiness issues in these datasets. \n",
    "- The scope of this project only limited us to finding these 10 issues. The aim of this project was simply to give the student an understanding of the fundamental principles of the data wrangling process and how to apply them on real world data.\n",
    "- Although some of the rating numerators may seem odd as they are above the numerator value of 10, these were not cleaned as this is the rating system that @WeRateDogs uses.\n",
    "\n",
    "### Cleaning\n",
    "- We followed the:\n",
    "    - Define, Code and Test methodology to clean the issues we had found in the 'Assess' stage.\n",
    "- Before we cleaned the datasets, we made copies of each separate dataset.\n",
    "- We did not change the `rating_denominator` values to 10 as it is not always 10.\n",
    "- We found the following issues which we cleaned:\n",
    "    >\n",
    "    - __Quality Issues:__\n",
    "        1. Removed the retweets from the df_twitter_archive_clean dataset.\n",
    "        \n",
    "        2. Changed the `tweet_id` data type from integer to string in all 3 datasets.\n",
    "\n",
    "        3. Changed the `timestamp` data type from string to datetime in the df_twitter_archive_clean dataset.\n",
    "\n",
    "        4. Changed the `rating_numerator` data type from integer to float in the df_twitter_archive_clean dataset.\n",
    "\n",
    "        5. Dropped the 59 null valued `expanded_urls` columns in the df_twitter_archive_clean dataset.\n",
    "\n",
    "        6. Removed the non-dog names in the `name` column in the df_twitter_archive_clean dataset.\n",
    "\n",
    "        7. Changed all the dog breed types in `p1, p2, p3` to lower case in the image_predictions_clean dataset.\n",
    "\n",
    "        8. Extracted the numerator ratings from the tweet text and replaced the values in the `rating_numerator` column in the df_twitter_archive_clean dataset.\n",
    "\n",
    "        9. Removed the '/' character from the `rating_numerator` column values in the df_twitter_archive_clean dataset so we could convert the column data type to integer.\n",
    "\n",
    "        10. Dropped the tweet related columns in the df_twitter_archive_clean dataset.\n",
    ">        \n",
    "    - __Tidiness Issues:__\n",
    "        11. Combined the dog stage columns into one column called `stage` with the values being the dog stages.\n",
    "        \n",
    "        12. Combined all three cleaned datasets into one master dataset called df_twitter_master."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "\n",
    "We stored the cleaned master dataset in a master file called __twitter_archive_master.csv__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing and Visualing Data\n",
    "We made 3 insights and 2 visualisations from the master dataset we had created."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
